I just wanted to take this opportunity to convince you that you need statistics in your research life.

For generations, we learned statistics in a very dry way. We learned a set of techniques to be applied in different situations with more focus on the mathematical theory than understanding why that specific technique is used there and what challenges arise when trying to use data to answer questions.

This traditional view of statistics as a bag tools is now facing major challenges. We are in the age of data science now. We are collecting unprecedented amounts of data in every field. And it's not just marketing data from Amazon purchases or social media posts that I'm talking about but biomedical data as well. If you think about this course, we are working with mRNA quantification. Existence of mRNA was finally proven in 1961, so it was just 60 years ago we could isolate mRNA, and now we are able to routinely profile whole mRNA repertoire of any cell. We can even do this in single-cell level. We can even do that in single-cell level for whole organs or whole organisms. More data means that we need to be even more aware of what the evidence is actually worth.

This ties well with the concept of data literacy. It refers to the ability to not only carry out statistical analysis on real-world problems, but also to understand and critique any conclusions drawn by others on the basis of statistics. With this course, you will be equipped with concepts and tools for you to analyze your own RNA-seq data, but also you will gain the ability to have a critical eye on any published RNA-seq data. We are answering more and more biomedical problems with data these days, be it sequencing or imaging or mass spec. And to be able to maintain a critical eye on any published research paper, you need statistics.

And what I mean by that, is that you need statistics as an investigative process of problem-solving and decision making. To formalize that, I want to briefly introduce the PPDAC cycle. When you want to answer a problem with data, what you actually do is to follow a statistical enquiry circle. And this is actually the framework that we follow or need to follow in any data analysis project. This is the framework we are following in this course/  And I'll demonstrate it with the case study we are working on for this course. As mentioned before, we are working with the data generated by Hu and collegaues.

And our cycle starts with a problem. Here the problem is toxoplasma infection is causing severe neurological disorders in some invididuals, but our understanding of the molecular mechanisms associated with infection is incomplete.

...

So this was just my propoganda for statistics - you actually need and use statistical concepts in your data driven research projects, and the complex looking formula containing part is just one component. And we will now talk about that component.

Good experimental design means that we will have reproducible research.

In recent years there has been increase in retraactions. You can take this graph in two ways: you can say that we are doing good, we are doing our due diligance and spot errors in results. Or we can

Retractions do not usually happen because of outright fabrication but because  we sometimes use an inappropriate statistical test, or we can mistakes and switch our samples, or we make an error in coding during analysis, or we can't replicate results or there was not enough power to support the claim that we are making. All of those are potentially caused by not having good experimental design from the outset.

This is rather a grim outcome of bad experimental design, this is your worst nightmare - having your publication retracted. But there are other consequences, there is obviously a cost issue. Sequencing is not cheap and no matter how many samples you sequence, there is no guarantee that you will get meaningful biological results without the correct design. Materials can be limited - this is especially true with clincal samples, when you are working with patient samples you can't obtain more samples. Immortalisation as we have talked about. And also if you put out something that's not right, and someone builds on that and doesn't necessarily realize than you are just perpetuating the problem. And also there are ethical concerns with that not just with patients but also with animals - if you cull 20 mice for an experiment and then the experiment turns out worthless, the you wasted 20 mice lives.

So what is a well designed experiment ? It should have clear objective, and by that I mean really specific questions. Not just I want to see what gene expression changes are but rather how is this pathway affected. Something a lot more specific than a fishing expedition.

I'll introduce some terminology about experimental design here. Experimental factors all the things you need to think about ahead of time. Things that will influence the outcome of the experiment. Obviously it is going to depend on the type of experiment you are doing: if you are doing in vivo mouse work it can be the cage number, feeding time, sex of mice. Or if you are working with clinical samples it can be ethnicity, country, sex etc. These are all the things that you want to think about.

Then we have the categorisation of these variables into different variable types. You all know what I mean by this variable types, but things you might want to consider can be if you have continuous variables will you have to categorise them and how will that affect your analysis. For instance, if you are measuring the weights of your mice, you might want to bin the weights or make ordinal categories like light-weight, medium-weight and heavy-weight. How do you decide on the thresholds might have an effect on how your experiment turns out - so you need to keep these in mind.

And then you get independent and dependent variables. Independent variable is what you change and dependent variable is what changes due to independent variable. Independent variable can be diet of a mice and dependent variable can be weight of a mice. Different diets for mice can cause a change in weight of a mice, but the weight doesn't cause a change in diet.

The ultimate goal is to explain dependent variable using independent variables in a model or in a function. We want to see the effect of our independent variable in dependent variable. If we go back to the previous example, we want to see if different diets affect weight of mice. But no model is perfect, and there is always an error margin, a noise. And in our setting, there are two components to it: biological and technical. Biological noise is due to inherent stochastic nature of biological processes. No human is identical, no mice is identical to the next one, biological systems are complex and stochastic. And we see this stochasticity in single cells, in cell populations, indivuals organs etc. And this can be due to timepoints or cell cycle phases. If you are collecting samples in different days - the time you extract RNA can have an affect on your results, or the cell cycle phase of your samples have an affect. You would want to minimize these effects as much as possible. It's not always possible, but you should realize that these things might make a difference.
And then we have technical noise, and these are due to really technical things such as different batches of reagents, antibodies, different temperatures. When you put them on a sequencer, different sequencing platforms, different runs, different operators. etc.
Consider these things in advance and make as many replicates as you can.

This brings us to the types of replication. We have biological and technical replication. Biological replication is really the crux of the matter in RNA-seq analysis. In vivo, this would be different patients, different mice etc. In vitro, it's a little bit different. In an ideal world, you would have different cell lines as replicates. But in reality, you don't always have multiple cell lines that have a certain characteristic you're looking for. And the way you got around this is to have different passages as replicates. Cell lines are quite homogoenous but it's not rare to see differences in expression profile between passages. You can see an example in this PCA plot, where pink is repsonsive cells and blue is resistant cells, and you can see a nice seperation on PCA, and they can now claim this seperation is due to resistant/responsive phenotype and not due to cell line differences. They can make a more universal claim now rather than saying that we observed this in one cell line. So having true biological replicates in this example adds more weight their argument.

The other type of replication is technical replicates. These are for checking your methodology.

Inevitably someone will ask how many replicates are required for an RNA-seq analysis, the short answer is lots. But in practical world, there are going to be logistical problems: how many RNA extractions you can do, how much grant money you have etc. All these things are going to play a role. If you got cell lines 4-6, if you got mice more than that as a rule of thumb. But don't take my word for it, plan an experimental design meeting with your bioinformatics core, with your local statistician, and come up with a reasonable number of replicates for your experiment.

Another point you need to think about are confounding factors. If you don't pay attention, you would trip you up. They are things that might mask an actual biological effect, or might make you think there is a biological effect when there isn't one. This hypothetical example in this slide describes a study where they measure coffee consumption and lung cancer incidence in a group of people and they see a correlation there. The group that drank more coffee had more lung cancer incidence, but what they forgot to check is if those people smoke. It could be that people who drink more coffee might be the people who smoke that take a coffee with their cigarette break. A relevant example in the context of RNAseq might be that you prepare all your controls on Monday, and all your treated samples on Tuesday. And when you perform your analysis you don't know if there is a difference due to the day of sample prep or a real biological effect. So these are things that you need to think about in your experimental setting - it's to prompt you to think ahead of time.

Solutions: First solution is to write it all down. What really helps is to have a metadata spreasheet where you record every little detail about these samples such as age, prep day, the person who did the prep, lot of antibody etc. Because, once you have such data, you can plot a PCA and color it according to all these factors and if we something slighly odd, something like a batch effect, we can start to account for that.
The second thing is randomization. All of the statistical analysis assume everything is randomized. You should avoid things like doing all your controls in one day and all your treatments the next. You need to randomize control/treatment arms across sample prep days so that you can see if there is a sample prep day effect.
The other way of controlling for technical effects is blinding. This term may come familiar from clinical trials but it also has relevance in this context. For instance, if there are two people who are doing sample prep for your RNA-seq experiment, it might be a good idea to introduce blinding. It's really to mitigate all technical biases.

This is an example of randomized block design. When you are submitting your samples to sequencing, they will ask you to submit your samples on a plate. In this example, we have three nine-well plates. And insteadof having all controls in one plate, all treatment 1 in one plate and all treatment 2 in one plate, It is much better to randomize them like you see here.

Here I have a real world example of this. You can see in this PCA each of the different colors is a different plate. You can see that they are clustering by color, there is a plate effect. And you can see that they have so many samples, and if they haven't done randomization this would have been a big problem. But luckily, they have randomized case and control into each plate, and you can see an even distribution of blue and green in all plates. So they effectively control for plate effect.

Experimental controls - in an ideal everything is identical across conditions except the variable you are testing. Obviously, that is not the case in the real world, and we need to control these things as best as we can. So we control for false positives by including negative controls, and we control for false negatives by including positive controls. It is less common to see positive controls but if you can afford to include it in your design, it's always a good idea to a include it.
And we have technnical controls - these are the things that you normalize measurements against or these are the controls that enable to detect technical biases. A good example for that is the inclusion of PhiX in every sequencing run - if they don't see the PhiX reads pop up the way it should, than they know something is up with sequencing.  They might not be so relevant for a standard RNA-seq run, but if you're doing something bespoke, you might want to think about that.

Some examples of experimental controls:
